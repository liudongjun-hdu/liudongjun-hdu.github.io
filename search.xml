<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>服务器包环境迁移</title>
      <link href="2021/03/26/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8C%85%E7%8E%AF%E5%A2%83%E8%BF%81%E7%A7%BB/"/>
      <url>2021/03/26/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8C%85%E7%8E%AF%E5%A2%83%E8%BF%81%E7%A7%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="服务器包环境迁移"><a href="#服务器包环境迁移" class="headerlink" title="服务器包环境迁移"></a>服务器包环境迁移</h1><h2 id="包环境导出"><a href="#包环境导出" class="headerlink" title="包环境导出"></a>包环境导出</h2><ol><li>输出包环境至文件：<pre><code>pip freeze | tee requirements.txt</code></pre></li></ol><h2 id="包环境导入"><a href="#包环境导入" class="headerlink" title="包环境导入"></a>包环境导入</h2><ol><li>从文件输出包环境：<pre><code>pip install -r requirements.txt</code></pre></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 服务器 </tag>
            
            <tag> 包环境 </tag>
            
            <tag> 迁移 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CapsNet动态路由算法</title>
      <link href="2021/03/23/CapsNet%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%E7%AE%97%E6%B3%95/"/>
      <url>2021/03/23/CapsNet%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="CapsNet动态路由算法"><a href="#CapsNet动态路由算法" class="headerlink" title="CapsNet动态路由算法"></a>CapsNet动态路由算法</h1><h2 id="CapsNet介绍"><a href="#CapsNet介绍" class="headerlink" title="CapsNet介绍"></a>CapsNet介绍</h2><ol><li>CapsNet的提出<br>深度学习开创者之一、反向传播等神经网络经典算法的发明人Geoffrey Hinton思考了胶囊网络数十年之久，才发表论文正式提出胶囊网络。主要原因就是一直没找到训练胶囊网络的合适算法。</li><li>CapsNet的优势<br>相比CNN需要的数据，它只需要学习一小部分数据，就能达到最先进的效果（Hinton在他关于CNN错误的著名演说中提到了这一点）。 从这个意义上说，胶囊理论实际上更接近人脑的行为。为了学会区分数字，人脑只需要几十个例子，最多几百个例子。而CNN则需要几万个例子才能取得很好的效果。这看起来像是在暴力破解，显然要比我们的大脑低级。</li></ol><h2 id="胶囊的概念"><a href="#胶囊的概念" class="headerlink" title="胶囊的概念"></a>胶囊的概念</h2><ol><li>胶囊概念的理解<br>“人工神经网络不应当追求“神经元”活动中的视角不变性（使用单一的标量输出来总结一个局部池中的重复特征检测器的活动），而应当使用局部的“胶囊”，这些胶囊对其输入执行一些相当复杂的内部计算，然后将这些计算的结果封装成一个包含信息丰富的输出的小向量。每个胶囊学习辨识一个有限的观察条件和变形范围内隐式定义的视觉实体，并输出实体在有限范围内存在的概率及一组“实例参数”，实例参数可能包括相对这个视觉实体的隐式定义的典型版本的精确的位姿、照明条件和变形信息。当胶囊工作正常时，视觉实体存在的概率具有局部不变性——当实体在胶囊覆盖的有限范围内的外观流形上移动时，概率不会改变。实例参数却是“等变的”——随着观察条件的变化，实体在外观流形上移动时，实例参数也会相应地变化，因为实例参数表示实体在外观流形上的内在坐标。”</li><li>使用胶囊<br>所有胶囊检测中的特征的状态的重要信息，都将以向量的形式（神经元输出的则是标量）被胶囊封装。胶囊将特征检测的概率作为其输出向量的长度进行编码。检测出的特征的状态被编码为该向量指向的方向（“实例参数”）。所以，当检测出的特征在图像中移动或其状态不知怎的发生变化时，概率仍然保持不变（向量长度没有改变），但它的方向改变了。胶囊将特征检测的概率作为其输出向量的长度进行编码。检测出的特征的状态被编码为该向量指向的方向（“实例参数”）。所以，当检测出的特征在图像中移动或其状态不知怎的发生变化时，概率仍然保持不变（向量长度没有改变），但它的方向改变了。</li><li>举例<br>想象一个胶囊，它检测图像中的面部，并输出长度为0.99的三维向量。接着我们开始在图像上移动面部。向量将在空间上旋转，表示检测出的面部的状态改变了，但其长度将保持固定，因为胶囊仍然确信它检测出了面部。这就是Hinton所说的活动等变性：神经活动将随着物体在图像中的“外观流形上的移动”而改变。与此同时，检测概率保持恒定，这才是我们应该追求的那种不变性，而不是CNN提供的基于最大池化的不变性。</li><li>胶囊的工作原理<br>胶囊和神经元的不同<br><img src="/images/capsule.png" alt="capsule"><ol><li>输入向量的矩阵乘法</li><li>输入向量的标量加权</li><li>加权输入向量之和</li><li>向量到向量的非线性变换 </li></ol></li></ol><h2 id="动态路由算法"><a href="#动态路由算法" class="headerlink" title="动态路由算法"></a>动态路由算法</h2><ol><li>算法的伪代码<br><img src="/images/routingalgorithm.png" alt="routingalgorithm"></li><li>算法的实现代码</li></ol><pre><code>def squash(x):    lengths2 = x.pow(2).sum(dim=2)    lengths = lengths2.sqrt()    x = x * (lengths2 / (1 + lengths2) / lengths).view(x.size(0), x.size(1), 1)    return xclass AgreementRouting(nn.Module):    def __init__(self, input_caps, output_caps, n_iterations):        super(AgreementRouting, self).__init__()        self.n_iterations = n_iterations        self.b = nn.Parameter(torch.zeros((input_caps, output_caps)))            def forward(self, u_predict):        batch_size, input_caps, output_caps, output_dim = u_predict.size()        c = F.softmax(self.b, dim=1)        s = (c.unsqueeze(2) * u_predict).sum(dim=1) #dim=0纵向压缩，dim=1横向压缩        v = squash(s)        if self.n_iterations &gt; 0:            b_batch = self.b.expand((batch_size, input_caps, output_caps))            for r in range(self.n_iterations):                v = v.unsqueeze(1)                b_batch = b_batch + (u_predict * v).sum(-1)                 c = F.softmax(b_batch.view(-1, output_caps), dim=1).view(-1, input_caps, output_caps, 1)                s = (c * u_predict).sum(dim=1)                v = squash(s)        return v</code></pre><ol start="3"><li>算法解读<ol><li>初始化一个权值矩阵b</li><li>b经过softmax得到系数c的值</li><li>系数c乘以u得到s</li><li>s经过非线性变换得到v<br>重复n_iteratons轮：<ol><li>计算u与v的相关性来更新b</li><li>b经过softmax得到系数c的值</li><li>系数c乘以u得到s</li><li>s经过非线性变换得到v </li></ol></li></ol></li></ol><h2 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h2><p>引用：<a href="https://blog.csdn.net/weixin_42182910">https://blog.csdn.net/weixin_42182910</a>  leonorandzzzz的博客</p>]]></content>
      
      
      
        <tags>
            
            <tag> CapsNet </tag>
            
            <tag> 动态路由算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo联合github创建网站</title>
      <link href="2021/03/23/hexo%E8%81%94%E5%90%88github%E5%88%9B%E5%BB%BA%E7%BD%91%E7%AB%99/"/>
      <url>2021/03/23/hexo%E8%81%94%E5%90%88github%E5%88%9B%E5%BB%BA%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<h1 id="hexo联合github创建网站"><a href="#hexo联合github创建网站" class="headerlink" title="hexo联合github创建网站"></a>hexo联合github创建网站</h1><h2 id="需要下载安装的软件"><a href="#需要下载安装的软件" class="headerlink" title="需要下载安装的软件"></a>需要下载安装的软件</h2><ol><li>安装Git<br>下载地址：<a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></li><li>安装Node.js<br>下载地址：<a href="https://nodejs.org/en/download/">https://nodejs.org/en/download/</a><br>注意：安装Node.js会包含环境变量及npm的安装<br>检测Node.js是否安装成功：在命令行输入 node -v:查看版本<br>检测npm是否安装成功：在命令行输入 npm -v:查看版本</li></ol><h2 id="使用hexo搭建静态网页"><a href="#使用hexo搭建静态网页" class="headerlink" title="使用hexo搭建静态网页"></a>使用hexo搭建静态网页</h2><p>Hexo就是我们的个人博客网站的框架，这里需要自己在电脑常里创建一个文件夹，可以命名为blog，你可以更改文件夹的名称（记住文件夹的名称），Hexo框架与以后你自己发布的网页都在这个文件夹中。<br>进入命令行界面，cd到此文件夹目录：</p><ol><li>使用npm命令安装Hexo<pre><code>npm install -g hexo-cli</code></pre></li><li>安装完成后，初始化我们的博客<pre><code>hexo init      # 初始化npm install    # 安装组件</code></pre></li><li>网站雏形已经建好，检测查看<pre><code>hexo new test_my_site #用于新建一篇文章hexo g #用于生成hexo s #建立服务</code></pre>完成后，打开浏览器输入地址：localhost:4000，即可查看到自己的静态网页。</li></ol><h2 id="使用github创建仓库"><a href="#使用github创建仓库" class="headerlink" title="使用github创建仓库"></a>使用github创建仓库</h2><ol><li>注册github账号，注意用户名需要与你的博客网站文件夹名称一致，例如blog</li><li>创建仓库，用于存放你的博客网站，即为：将你的本地文件部署在github仓库里，用户即可在网上访问你的网站。<br>GitHub 主页右上角加号 -&gt; New repository：<br><img src="/images/repository.jpg" alt="repository"><br>填好后点击 Create repository 创建<br>创建后默认自动启用 HTTPS，博客地址为：https://用户名.github.io</li></ol><h2 id="hexo与github联动"><a href="#hexo与github联动" class="headerlink" title="hexo与github联动"></a>hexo与github联动</h2><ol><li>在联动之前，需要将你的Git与GitHub账号绑定：<ol><li>进入你的文件夹，鼠标右击打开Git Bash<br>设置user.name和user.email配置信息：<pre><code>git config --global user.name &quot;你的GitHub用户名&quot;git config --global user.email &quot;你的GitHub注册邮箱&quot;</code></pre></li><li>生成ssh密钥文件：<pre><code>ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;</code></pre></li><li>然后直接三个回车即可，默认不需要设置密码<br>然后找到生成的.ssh的文件夹中的id_rsa.pub密钥，将内容全部复制</li><li>打开GitHub_Settings_keys 页面，新建new SSH Key<br><img src="/images/key.jpg" alt="key"><br>Title为标题，任意填即可，将刚刚复制的id_rsa.pub内容粘贴进去，最后点击Add SSH key。</li><li>在Git Bash中检测GitHub公钥设置是否成功，输入 ssh <a href="mailto:&#x67;&#105;&#116;&#x40;&#103;&#x69;&#116;&#x68;&#117;&#x62;&#46;&#99;&#x6f;&#109;">&#x67;&#105;&#116;&#x40;&#103;&#x69;&#116;&#x68;&#117;&#x62;&#46;&#99;&#x6f;&#109;</a> ：<br><img src="/images/ssh.jpg" alt="ssh"><br>如上则说明成功。这里之所以设置GitHub密钥原因是，通过非对称加密的公钥与私钥来完成加密，公钥放置在GitHub上，私钥放置在自己的电脑里。GitHub要求每次推送代码都是合法用户，所以每次推送都需要输入账号密码验证推送用户是否是合法用户，为了省去每次输入密码的步骤，采用了ssh，当你推送的时候，git就会匹配你的私钥跟GitHub上面的公钥是否是配对的，若是匹配就认为你是合法用户，则允许推送。这样可以保证每次的推送都是正确合法的。</li></ol></li><li>本地博客测试成功后，就是上传到 GitHub 进行部署，使其能够在网络上访问。<ol><li>在blog根目录里的_config.yml文件称为站点配置文件<br>添加或修改文件如下，注意有空格<br>deploy:<br>type: git<br>repo: 这里填入你之前在GitHub上创建仓库的完整路径，记得加上 .git<br>branch: master<br>保存站点配置文件。<br>解释：其实就是给hexo d 这个命令做相应的配置，让hexo知道你要把blog部署在哪个位置，很显然，我们部署在我们GitHub的仓库里。</li><li>安装Git部署插件，输入命令：<pre><code>npm install hexo-deployer-git --save</code></pre></li><li>分别输入三条命令：<pre><code>hexo clean hexo g hexo d</code></pre>第三条的 hexo d 就是部署网站命令，d是deploy的缩写。完成后，打开浏览器，在地址栏输入你的放置个人网站的仓库路径，即 <a href="http://xxxx.github.io,你就会发现你的博客已经上线了,可以在网络上被访问了./">http://xxxx.github.io,你就会发现你的博客已经上线了，可以在网络上被访问了。</a></li></ol></li></ol><h2 id="常用命令介绍"><a href="#常用命令介绍" class="headerlink" title="常用命令介绍"></a>常用命令介绍</h2><p>npm install hexo -g #安装Hexo<br>npm update hexo -g #升级<br>hexo init #初始化博客</p><p>命令简写<br>hexo n “我的博客” == hexo new “我的博客” #新建文章<br>hexo g == hexo generate #生成<br>hexo s == hexo server #启动服务预览<br>hexo d == hexo deploy #部署</p><p>hexo server #Hexo会监视文件变动并自动更新，无须重启服务器<br>hexo server -s #静态模式<br>hexo server -p 5000 #更改端口<br>hexo server -i 192.168.1.1 #自定义 IP<br>hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令</p><h2 id="网站主题更换，功能优化升级"><a href="#网站主题更换，功能优化升级" class="headerlink" title="网站主题更换，功能优化升级"></a>网站主题更换，功能优化升级</h2><p>请访问：<a href="https://tqraf.cn/2020/04/hexoblog.html">https://tqraf.cn/2020/04/hexoblog.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
            <tag> 网站 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux服务器环境配置</title>
      <link href="2021/03/22/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>2021/03/22/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux服务器环境部署"><a href="#Linux服务器环境部署" class="headerlink" title="Linux服务器环境部署"></a>Linux服务器环境部署</h1><p>by 栋栋</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ol><li>vim操作：<ol><li>vim xxxxx</li><li>按i 进入编辑模式，光标移到对应位置进行插入</li><li>编辑好文本按Esc退出插入状态</li><li>保存退出命令 ：wq </li><li>删除一个目录，如（Anaconda3-5.3.1）：sudo rm -rf Anaconda3-5.3.1</li></ol></li></ol><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><ol><li>获取权限：sudo -i，切换至 root 超级用户目录 </li><li>创建用户：adduser ldj(你的名字) </li><li>设置密码：passwd ldj xxx(你的密码) </li><li>切换用户：su ldj 进入自己的用户目录 </li><li>如果你需要管理员权限的话，可切换至root目录，赋予用户文件修改权限： <ol><li>chmod u+w /etc/sudoers </li><li>vim /etc/sudoers 进入文件，添加语句：ldj ALL=(ALL) ALL </li><li>“:wq”保存并退出文件 </li><li>usermod -g root ldj 修改属组关系 </li><li>vim /etc/passwd 记住自己的ID，不要修改因为只是获取root权限而不是变成root用户</li><li>“:wq”保存并退出文件 </li><li>关闭文件修改权限：chmod u-w /etc/sudoers </li></ol></li></ol><h2 id="安装-anaconda"><a href="#安装-anaconda" class="headerlink" title="安装 anaconda"></a>安装 anaconda</h2><ol><li>下载 anaconda：sudo wget <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3</a>. 1-Linux-x86_64.sh </li><li>安装 anaconda：sudo bash Anaconda3-5.3.1-Linux-x86_64.sh(提前将文件下载到你的目录)</li><li>配置环境变量：</li><li>编辑配置文件：vi ~/.bashrc（配置该用户的环境变量）</li><li>最后添加一行：export PATH=/home/ldj/anaconda3/bin:$PATH</li><li>激活安装：source ~/.bashrc</li><li>验证是否安装成功：conda –version 查看版本，conda list 查看包列表</li></ol><h2 id="安装-cuda-和-cudnn"><a href="#安装-cuda-和-cudnn" class="headerlink" title="安装 cuda 和 cudnn"></a>安装 cuda 和 cudnn</h2><ol><li>版本匹配表<br><img src="/images/versionmatching1.jpg" alt="版本匹配表"><br><img src="/images/versionmatching2.jpg" alt="版本匹配表"><br>注释：因为我们实验室服务器已经安装好驱动了，为了减少篇幅，所以省略安装驱动步骤，有需要可以自行百度。<br>nvidia-smi，有如下显示则说明驱动安装成功：<br><img src="/images/versionmatching3.jpg" alt="版本匹配表"></li><li>linux 服务器安装 cuda <ol><li>下载 cuda:sudo wget -c <a href="https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run">https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run</a></li><li>安装 cuda:sudo sh cuda_9.0.176_384.81_linux-run </li></ol></li><li>linux 服务器安装 cudnn <ol><li>下载 cudnn：sudo wget -c <a href="https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.1.4/prod/9.0_20180516/cudnn-9.0-linux-x64-v7.1">https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.1.4/prod/9.0_20180516/cudnn-9.0-linux-x64-v7.1</a> </li><li>安装 cudnn：tar -xzvf /home/ldj/cuda/cudnn-9.0-linux-x64-v7.1.tgz -C </li><li>配置 cudnn: <ol><li>将cudnn的文件移动到cuda文件目录下</li><li>cuda软连接地址在安装过程中会建议一个软连接：会在/usr/local/下面建立一个软连接cuda该软连接连接到安装的真正的cuda-10.0的地址。</li><li>软连接的建立可以用于多个版本的cuda的管理。<br>sudo cp cuda/include/cudnn.h    /usr/local/cuda-9.0/include<br>sudo cp cuda/lib64/libcudnn*    /usr/local/cuda-9.0/lib64<br>sudo chmod a+r /usr/local/cuda-9.0/include/cudnn.h   /usr/local/cuda-9.0/lib64/libcudnn*</li></ol></li></ol></li><li>配置用户环境变量:<br>sudo vim ~/.bashrc<br>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64<br>export PATH=$PATH:/usr/local/cuda/bin</li><li>激活：source ~/.bashrc 使新配置的环境变量生效 </li><li>验证是否成功：nvcc -V：查看是否安装成功 </li><li>查看位置：which NV：查看 NV 位置 </li></ol><h2 id="配置个人环境"><a href="#配置个人环境" class="headerlink" title="配置个人环境"></a>配置个人环境</h2><ol><li>在 anaconda 下建立自己的虚拟环境： <ol><li>建立环境：conda create -n name python=3.6,name:虚拟环境 名称，python 版本自己更改 </li><li>查看环境：conda env list （查看所有环境） </li><li>激活环境：source activate name（环境名称为 name），进入创建的 name 环境 </li></ol></li><li>安装 tensorflow-gpu 版，输入 pip install tensorflow-gpu==1.8.0,版本号自己更换。<br>输入 python 回车，输入 import tensorflow，如果没有报错说明 tensorflow 配置成功。<br>也可使用下面的代码进行测试： <pre><code>import tensorflow as tf hello = tf.constant(&#39;Hello, TensorFlow!&#39;)sess = tf.Session() print(sess.run(hello)) </code></pre></li><li>安装 keras-gpu 版，输入 pip install keras-gpu==2.1.4,版本号 自己更换。<br>输入 python 回车，输入 import keras，如果没有报错说明 keras 配置成功，其他环境同上方法配置 </li><li>关闭环境：source deactivate py36_wyh</li></ol><h2 id="安装-pycharm"><a href="#安装-pycharm" class="headerlink" title="安装 pycharm"></a>安装 pycharm</h2><ol><li>下载 pycharm：<a href="https://www.jetbrains.com/pycharm/download/">https://www.jetbrains.com/pycharm/download/</a> </li><li>安装 pycharm： tar -zxvf pycharm-community-2020.2.3.tar.gz 3.启动 pycharm：bin 文件夹下输入./pycharm.sh 启动 pycharm<br>cd /home/ldj/pycharm-community-2020.2.3/bin/<br>./pycharm.sh </li></ol><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ol><li>安装一定要在自己的目录下进行，以免更改他人环境 </li><li>在安装之前配置清华镜像，下载速度会很快，更换下载源的方法如 下: 在自己的目录下新建一个.pip 文件夹，在.pip 文件夹下新建 pip.conf 文件，内容为：<br>[global] index-url = <a href="https://pypi.douban.com/simple/">https://pypi.douban.com/simple/</a><br>[install] trusted-host = <a href="https://pypi.douban.com/simple/">https://pypi.douban.com/simple/</a><br>几个常用的国内源，大家可以自己选择，替换文件中的网址就可以：<br>阿里云 <a href="http://mirrors.aliyun.com/pypi/simple/">http://mirrors.aliyun.com/pypi/simple/</a> 中国科技大学 <a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a><br>豆瓣(douban) <a href="http://pypi.douban.com/simple/">http://pypi.douban.com/simple/</a> 清华大学 <a href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a><br>中国科学技术大学 <a href="http://pypi.mirrors.ustc.edu.cn/simple/">http://pypi.mirrors.ustc.edu.cn/simple/</a> </li><li>conda更换清华源<br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</a><br>由于后续还要进行PyTorch安装，还要增加PyTorch源<br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</a><br>设置搜索时显示通道地址<br>conda config –set show_channel_urls yes<br>编辑conda的配置文件：vi ~/.condarc<br>删除第三行“- defaults”，然后wq保存退出即可。<br>换源成功后输入如下命令进行更新：<br>conda update –all<br>conda update -n base conda</li><li>实验室的cuda和cudnn一般都是配置好的，直接引用即可。避免重复下载，浪费空间。</li><li>跑程序时，加上 os.environ[“CUDA_VISIBLE_DEVICES”]=”0”,0 是 GPU 标志，更换数字即更换 GPU </li><li>注意区分命令前有无 sudo 的区别，sudo为增加权限使用。 </li><li>升级pip：pip install –upgrade pip</li><li>启动pyCharm的命令设置别名：<br><a href="https://blog.csdn.net/hay54/article/details/82344014">https://blog.csdn.net/hay54/article/details/82344014</a><br>alias luminarypy=’cd /home/wyh/pycharm-community-2020.2.3/bin/;./pycharm.sh’<br>luminarypy可打开pycharm<br>alias命令，查看所有别名<br>unalias 别名，表示取消某个别名。<br>注意：alias命令只作用于当次登入的操作。如果想每次登入都能使用这些命令的别名，则可以把相应的alias命令存放在 ~/.bashrc 文件中<br>操作：vi ~/.bashrc<br>找到alias命令那边加入：alias luminarypy=’cd /home/wyh/pycharm-community-2020.2.3/bin/;./pycharm.sh’<br>然后激活：source ~/.bashrc<br>这样别名就永久生效了</li></ol><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>  杭州电子科技大学计算机学院 lab519 刘栋军 联系方式：<a href="mailto:&#108;&#x69;&#x75;&#100;&#111;&#110;&#103;&#106;&#x75;&#x6e;&#64;&#104;&#x64;&#117;&#46;&#101;&#x64;&#x75;&#x2e;&#99;&#x6e;">&#108;&#x69;&#x75;&#100;&#111;&#110;&#103;&#106;&#x75;&#x6e;&#64;&#104;&#x64;&#117;&#46;&#101;&#x64;&#x75;&#x2e;&#99;&#x6e;</a> </p><h2 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h2><p>  本文部分引用 csdn 博客等网络内容，如有侵权，请联系本人删除， 谢谢。<br>  本人才疏学浅，如有错误，请联系本人更改，谢谢。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 服务器 </tag>
            
            <tag> 环境部署 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>字体设置</title>
      <link href="2021/03/22/%E5%AD%97%E4%BD%93%E8%AE%BE%E7%BD%AE/"/>
      <url>2021/03/22/%E5%AD%97%E4%BD%93%E8%AE%BE%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<ol><li>设置,路径是你的字体文件存放的路径<pre><code>zhfont1 = matplotlib.font_manager.FontProperties(fname=&#39;/usr/share/fonts/my_fonts/simhei.ttf&#39;)</code></pre></li><li>使用<pre><code>plt.xlabel(&#39;预测类别&#39;, fontsize=20, fontproperties=zhfont1)plt.ylabel(&#39;真实类别&#39;, fontsize=20, fontproperties=zhfont1)</code></pre></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 字体 </tag>
            
            <tag> 中英文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>绘图</title>
      <link href="2021/03/21/%E7%BB%98%E5%9B%BE/"/>
      <url>2021/03/21/%E7%BB%98%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h1><h2 id="绘图需要引入的包以及图片存储路径"><a href="#绘图需要引入的包以及图片存储路径" class="headerlink" title="绘图需要引入的包以及图片存储路径"></a>绘图需要引入的包以及图片存储路径</h2><p>import matplotlib.pyplot as plt<br>import matplotlib<br>from sklearn.metrics import *<br>import matplotlib.pyplot as plt<br>import numpy as np<br>exp_root = ‘/home/wyh/Python_workspace/DAN_EEGIMAGE_CODE/model_indices/‘</p><h2 id="横向对比图"><a href="#横向对比图" class="headerlink" title="横向对比图"></a>横向对比图</h2><pre><code>def Comparsion_regression():    # 构建数据    x_data = [&#39;愤怒&#39;, &#39;快乐&#39;, &#39;中立&#39;, &#39;悲伤&#39;, &#39;惊奇&#39;, &#39;厌恶&#39;, &#39;恐惧&#39;]    y_data1 = [100.00, 92.31, 100.00, 83.33, 83.33, 50.00, 37.50]    y_data2 = [100.00, 96.15, 100.00, 83.33, 91.67, 62.50, 37.50]    bar_width = 0.4    # Y轴数据使用range(len(x_data), 就是0、1、2...    plt.barh(y=range(len(x_data)), width=y_data1, label=&#39;IMAGE&#39;, color=&#39;steelblue&#39;, alpha=0.8, height=bar_width)    # Y轴数据使用np.arange(len(x_data))+bar_width,    # 就是bar_width、1+bar_width、2+bar_width...这样就和第一个柱状图并列了    plt.barh(y=np.arange(len(x_data)) + bar_width, width=y_data2, label=&#39;EEG-LIKE&#39;, color=&#39;indianred&#39;, alpha=0.8,             height=bar_width)    # 在柱状图上显示具体数值, ha参数控制水平对齐方式, va控制垂直对齐方式    for y, x in enumerate(y_data1):        plt.text(x - 6, y - bar_width / 2, &#39;%s&#39; % (x), ha=&#39;center&#39;, va=&#39;bottom&#39;)    for y, x in enumerate(y_data2):        plt.text(x - 6, y + bar_width / 2, &#39;%s&#39; % (x), ha=&#39;center&#39;, va=&#39;bottom&#39;)    # 为Y轴设置刻度值    plt.yticks(np.arange(len(x_data)) + bar_width / 2, x_data)    # 设置标题    plt.title(&quot;Comparison graph of accuracy before and after regression&quot;)    # 为两条坐标轴设置名称    plt.xlabel(&quot;Accuracy(%)&quot;)    plt.ylabel(&quot;Emotional categories&quot;)    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)    # 显示图例    plt.legend(loc=&#39;upper right&#39;)    plt.savefig(&quot;/home/wyh/Python_workspace/DAN_EEGIMAGE_CODE/model_indices/DualChart.jpg&quot;)    plt.show()</code></pre><p><img src="/images/DualChart.jpg" alt="横向对比图"></p><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><pre><code>def plot_confusion_matrix(y_true, y_pred, labels):  # 计算混淆矩阵，以评估分类的准确性。    cmap = plt.cm.binary    cm = confusion_matrix(y_true, y_pred)    tick_marks = np.array(range(len(labels))) + 0.5    np.set_printoptions(precision=2)    cm_normalized = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis]    plt.figure(figsize=(20, 18), dpi=120)    ind_array = np.arange(len(labels))    x, y = np.meshgrid(ind_array, ind_array)    intFlag = 0    for x_val, y_val in zip(x.flatten(), y.flatten()):        #        if (intFlag):            c = cm[y_val][x_val]            plt.text(x_val, y_val, &quot;%d&quot; % (c,), color=&#39;black&#39;, fontsize=20, va=&#39;center&#39;, ha=&#39;center&#39;)        else:            c = cm_normalized[y_val][x_val]            if (c &gt; 0.80):                plt.text(x_val, y_val, &quot;%0.2f&quot; % (c * 100,), color=&#39;white&#39;, fontsize=20, va=&#39;center&#39;, ha=&#39;center&#39;)            else:                plt.text(x_val, y_val, &quot;%0.2f&quot; % (c * 100,), color=&#39;black&#39;, fontsize=20, va=&#39;center&#39;, ha=&#39;center&#39;)    if (intFlag):        plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=cmap)    else:        plt.imshow(cm_normalized, interpolation=&#39;nearest&#39;, cmap=cmap)    plt.gca().set_xticks(tick_marks, minor=True)    plt.gca().set_yticks(tick_marks, minor=True)    plt.gca().xaxis.set_ticks_position(&#39;none&#39;)    plt.gca().yaxis.set_ticks_position(&#39;none&#39;)    plt.grid(True, which=&#39;minor&#39;, linestyle=&#39;-&#39;)    plt.gcf().subplots_adjust(bottom=0.15)    plt.title(&#39;&#39;)    plt.colorbar()    xlocations = np.array(range(len(labels)))    plt.xticks(xlocations, labels, rotation=90, fontsize=20, fontproperties=zhfont1)    plt.yticks(xlocations, labels, fontsize=20, fontproperties=zhfont1)    plt.ylabel(&#39;真实类别&#39;, fontsize=20, fontproperties=zhfont1)    plt.xlabel(&#39;预测类别&#39;, fontsize=20, fontproperties=zhfont1)    plt.savefig(exp_root + &#39;knn_confusion_matrix12.jpg&#39;, dpi=600)    plt.show()</code></pre><p><img src="/images/knn_confusion_matrix12.jpg" alt="混淆矩阵图"></p><h2 id="t-sne"><a href="#t-sne" class="headerlink" title="t-sne"></a>t-sne</h2><pre><code>def plot_embedding(data, label):    fig = plt.figure(figsize=(5, 5))    type1_x = []    type1_y = []    type2_x = []    type2_y = []    type3_x = []    type3_y = []    type4_x = []    type4_y = []    type5_x = []    type5_y = []    type6_x = []    type6_y = []    type7_x = []    type7_y = []    type8_x = []    type8_y = []    for i in range(data.shape[0]):        if label[i] == 0:            type1_x.append(data[i][0])            type1_y.append(data[i][1])        if label[i] == 1:            type2_x.append(data[i][0])            type2_y.append(data[i][1])        if label[i] == 2:            type3_x.append(data[i][0])            type3_y.append(data[i][1])        if label[i] == 3:            type4_x.append(data[i][0])            type4_y.append(data[i][1])        if label[i] == 4:            type5_x.append(data[i][0])            type5_y.append(data[i][1])        if label[i] == 5:            type6_x.append(data[i][0])            type6_y.append(data[i][1])        if label[i] == 6:            type7_x.append(data[i][0])            type7_y.append(data[i][1])        if label[i] == 7:            type8_x.append(data[i][0])            type8_y.append(data[i][1])    color = plt.cm.Set3(0)    color = np.array(color).reshape(1, 4)    color1 = plt.cm.Set3(1)    color1 = np.array(color1).reshape(1, 4)    color2 = plt.cm.Set3(2)    color2 = np.array(color2).reshape(1, 4)    color3 = plt.cm.Set3(3)    color3 = np.array(color3).reshape(1, 4)    type1 = plt.scatter(type1_x, type1_y, s=10, c=&#39;r&#39;)    type2 = plt.scatter(type2_x, type2_y, s=10, c=&#39;g&#39;)    type3 = plt.scatter(type3_x, type3_y, s=10, c=&#39;b&#39;)    type4 = plt.scatter(type4_x, type4_y, s=10, c=&#39;k&#39;)    type5 = plt.scatter(type5_x, type5_y, s=10, c=&#39;c&#39;)    type6 = plt.scatter(type6_x, type6_y, s=10, c=&#39;m&#39;)    type7 = plt.scatter(type7_x, type7_y, s=10, c=&#39;y&#39;)    type8 = plt.scatter(type8_x, type8_y, s=10, c=color)    plt.legend((type1, type2, type3, type4, type5, type6, type7, type8),               (&#39;愤怒&#39;, &#39;厌恶&#39;, &#39;恐惧&#39;, &#39;快乐&#39;, &#39;中立&#39;, &#39;悲伤&#39;, &#39;惊奇&#39;), prop=zhfont1)    plt.xticks()    plt.yticks()    return figdef visual_features(x_train_img, x_test_img, y_train, y_test):    from sklearn.manifold import TSNE    # 可视化训练/测试数据模式    X_train = x_train_img    Y_train = y_train    tsne = TSNE(n_components=2, init=&#39;pca&#39;, random_state=0)  # 使用TSNE对特征降到二维    reduce_dim_X = tsne.fit_transform(X_train)  # 降维后的数据    # 画图    # plt.subplot(1, 2, 1)    fig = plot_embedding(reduce_dim_X, Y_train)    # 图例过大，保存figure时无法保存完全，故对此参数进行调整    fig.subplots_adjust(right=0.7)    plt.title(&#39;图像视觉特征可视化&#39;, fontproperties=zhfont1)    plt.savefig(&quot;/home/wyh/Python_workspace/DAN_EEGIMAGE_CODE/model_indices/t-sne_train_image.jpg&quot;)    plt.show()    X_test = x_test_img    Y_test = y_test    tsne = TSNE(n_components=2, init=&#39;pca&#39;, random_state=0)  # 使用TSNE对特征降到二维    reduce_dim_X = tsne.fit_transform(X_test)  # 降维后的数据    # 画图    # plt.subplot(1, 2, 2)    fig = plot_embedding(reduce_dim_X, Y_test)    # 图例过大，保存figure时无法保存完全，故对此参数进行调整    fig.subplots_adjust(right=0.7)    plt.title(&#39;虚拟脑电情感特征可视化&#39;, fontproperties=zhfont1)    # plt.show()    plt.savefig(&quot;/home/wyh/Python_workspace/DAN_EEGIMAGE_CODE/model_indices/t-sne_train_EEG-LIKE.jpg&quot;)    plt.show()</code></pre><p><img src="/images/t-sne_train_image.jpg" alt="t-sne图1"><br><img src="/images/t-sne_train_EEG-LIKE.jpg" alt="t-sne图2"></p><h2 id="纵向对比图"><a href="#纵向对比图" class="headerlink" title="纵向对比图"></a>纵向对比图</h2><pre><code>def comparison_bar(IMAGE_score, Regression_score, Fusion_score, EEG_score):    X = [&#39;图像&#39;, &#39;回归&#39;, &#39;融合&#39;, &#39;脑电&#39;]    Y = [0.839080459770114, 0.873563218390804, 0.885057471264367, 0.977011494252873]    plt.xticks(fontproperties=zhfont1)    plt.bar(X, Y, 0.5, color=[&#39;green&#39;, &#39;blue&#39;, &#39;yellow&#39;, &#39;red&#39;])    plt.xlabel(&quot;方法&quot;, fontproperties=zhfont1)    plt.ylabel(&quot;准确率&quot;, fontproperties=zhfont1)    plt.title(&quot;方法对比图&quot;, fontproperties=zhfont1)    for a, b in zip(X, Y):        plt.text(a, b, &#39;%.4f&#39; % b, ha=&#39;center&#39;, va=&#39;bottom&#39;, fontsize=11)    # plt.show()    plt.savefig(&quot;/home/wyh/Python_workspace/DAN_EEGIMAGE_CODE/model_indices/BarChart.jpg&quot;)    plt.show()</code></pre><p><img src="/images/BarChart.jpg" alt="纵向对比图"></p><h2 id="折线图"><a href="#折线图" class="headerlink" title="折线图"></a>折线图</h2><pre><code>def EEG_like(x_test_eeg, y_pred_test):    x_test_eeg_average = x_test_eeg.mean(0)    x_test_like_average = y_pred_test.mean(0)    x1 = range(0, 128)    x2 = range(0, 128)    y1 = x_test_eeg_average    y2 = x_test_like_average    plt.subplot(2, 1, 1)    plt.plot(x1, y1, &#39;.-&#39;)    plt.title(&#39;脑电情感特征和虚拟脑电情感特征&#39;, fontproperties=zhfont1)    plt.ylabel(&#39;脑电情感特征&#39;, fontproperties=zhfont1)    # plt.xlabel(&#39;Time series&#39;,fontproperties=zhfont1)    plt.subplot(2, 1, 2)    plt.plot(x2, y2, &#39;.-&#39;)    plt.xlabel(&#39;模拟时间序列&#39;, fontproperties=zhfont1)    plt.ylabel(&#39;虚拟脑电情感特征&#39;, fontproperties=zhfont1)    # plt.show()    plt.savefig(&quot;/home/wyh/Python_workspace/DAN_EEGIMAGE_CODE/model_indices/EEG-LIKE.jpg&quot;)    plt.show()</code></pre><p><img src="/images/EEG-LIKE.jpg" alt="折线图"></p><h2 id="accuracy-loss图"><a href="#accuracy-loss图" class="headerlink" title="accuracy_loss图"></a>accuracy_loss图</h2><pre><code>x1 = range(0, iteration//log_interval)x2 = range(0, iteration//log_interval)y1 = Accuracy_listy2 = Loss_listplt.subplot(2, 1, 1)plt.plot(x1, y1, &#39;o-&#39;)plt.title(&#39;Train accuracy vs. epochs&#39;)plt.ylabel(&#39;Train accuracy&#39;)plt.subplot(2, 1, 2)plt.plot(x2, y2, &#39;.-&#39;)plt.xlabel(&#39;Train loss vs. epochs&#39;)plt.ylabel(&#39;Train loss&#39;)plt.savefig(&quot;/home/wyh/Python_workspace/DAN_EEGIMAGE_CODE/model_indices/accuracy_loss.jpg&quot;)plt.show()</code></pre><p><img src="/images/accuracy_loss.jpg" alt="accuracy_loss图"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 绘图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习零散知识点</title>
      <link href="2021/03/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9B%B6%E6%95%A3%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>2021/03/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9B%B6%E6%95%A3%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="reshape"><a href="#reshape" class="headerlink" title="reshape"></a>reshape</h2><pre><code>x_train = x_train.reshape(-1, height, width, channels).astype(&#39;float32&#39;)x_test = x_test.reshape(-1, height, width, channels).astype(&#39;float32&#39;)</code></pre><p>reshape更改数组形状，astype更改数值类型。</p><h2 id="to-categorical"><a href="#to-categorical" class="headerlink" title="to_categorical"></a>to_categorical</h2><pre><code>y_train = np_utils.to_categorical(y_train, n_classes) y_test = np_utils.to_categorical(y_test, n_classes)</code></pre><p>to_categorical就是将类别向量转换为二进制（只有0和1）的矩阵类型表示。其表现为将原有的类别向量转换为独热（onehot）编码的形式。</p><h2 id="keras数据增强"><a href="#keras数据增强" class="headerlink" title="keras数据增强"></a>keras数据增强</h2><pre><code>datagen = ImageDataGenerator(        rotation_range=10,        width_shift_range=0.1,        height_shift_range=0.1,        horizontal_flip=True,        shear_range=0.1,        zoom_range=0.1,        fill_mode=&#39;nearest&#39;)</code></pre><p>图像深度学习任务中，面对小数据集，我们往往需要利用Image Data Augmentation图像增广技术来扩充我们的数据集，而keras的内置ImageDataGenerator很好地帮我们实现图像增广。</p><h2 id="keras-flow函数"><a href="#keras-flow函数" class="headerlink" title="keras flow函数"></a>keras flow函数</h2><pre><code>for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True):flow(self, X, y, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;png&#39;)：</code></pre><p>接收numpy数组和标签为参数,生成经过数据提升或标准化后的batch数据,并在一个无限循环中不断的返回batch数据,flow_from_directory(directory): 以文件夹路径为参数,生成经过数据提升/归一化后的数据,在一个无限循环中无限产生batch数据。</p><h2 id="keras-自定义损失函数"><a href="#keras-自定义损失函数" class="headerlink" title="keras 自定义损失函数"></a>keras 自定义损失函数</h2><pre><code>def dice_coef(y_true, y_pred, lamb):    cross_loss= K.categorical_crossentropy(y_true,y_pred)    mmd_loss = keras.losses.kullback_leibler_divergence(y_true,y_pred)    return lamb * cross_loss + lamb * mmd_lossdef dice_loss(lamb):    def dice(y_true, y_pred):        return dice_coef(y_true, y_pred, lamb)    return dicedef my_loss(args, lamb):    y_true, y_pred, train_feature, test_feature = args[0], args[1], args[2], args[3]    mmd_loss = keras.losses.kullback_leibler_divergence(train_feature,test_feature)    cross_loss= K.categorical_crossentropy(y_true,y_pred)    return cross_loss + lamb*mmd_loss</code></pre><h2 id="keras-训练，使用自定义损失函数"><a href="#keras-训练，使用自定义损失函数" class="headerlink" title="keras 训练，使用自定义损失函数"></a>keras 训练，使用自定义损失函数</h2><pre><code>model.add(Dense(n_classes,activation=&#39;softmax&#39;))train_features = model.predict(x_train)test_features = model.predict(x_test)train_features = tf.convert_to_tensor(train_features)test_features = tf.convert_to_tensor(test_features)y_pred = model.predict(x_train)y_true = y_trainy_pred = tf.convert_to_tensor(y_pred)y_true = tf.convert_to_tensor(y_true)loss_body = layers.Lambda(my_loss, output_shape=(1,), name=&#39;my_loss&#39;, arguments=&#123;&#39;lamb&#39;:0.5&#125;)([y_true, y_pred, train_features, test_features])model.add(loss_body)sgd = SGD(lr=lr, decay=1e-5, momentum=0.9, nesterov=False)model.compile(loss=&#123;&#39;my_loss&#39;: lambda y_true, y_pred: y_pred&#125;, optimizer=sgd)</code></pre><h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><pre><code>model.save(&#39;路径&#39;)</code></pre><h2 id="维度切换"><a href="#维度切换" class="headerlink" title="维度切换"></a>维度切换</h2><pre><code>x_train = x_train.transpose(0, 3, 1, 2)x_test = x_test.transpose(0, 3, 1, 2)</code></pre><p>维度切换，将keras的AlextNet的输入的‘数量，长，宽，通道’修改为pytorch的‘数量，通道，长，宽’。</p><h2 id="获取扩增数据，联系第3点"><a href="#获取扩增数据，联系第3点" class="headerlink" title="获取扩增数据，联系第3点"></a>获取扩增数据，联系第3点</h2><pre><code>x_train_all = []y_train_all = []batches_train=0for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True):    x_train_all.append(x_batch)    y_train_all.append(y_batch)    batches_train+=1    if batches_train &gt;= times * len(x_train) / batch_size:        breakx_train_all = np.concatenate(x_train_all)y_train_all = np.concatenate(y_train_all)x_train_all = torch.tensor(x_train_all)y_train_all = torch.tensor(y_train_all)torch_data_train = GetLoader(x_train, y_train)  #dataloaderdatas_train = DataLoader(torch_data_train, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=0)</code></pre><h2 id="pytorch-训练-迁移学习"><a href="#pytorch-训练-迁移学习" class="headerlink" title="pytorch 训练 迁移学习"></a>pytorch 训练 迁移学习</h2><pre><code>model.train()    for e in range(epochs):        print(&#39;epochs:&#39;,e+1)        for j, data_train in enumerate(datas_train, 0):            lr_rate = lr / math.pow((1 +  (e * train_num + j) / epochs*train_num), 0.5)            optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate, momentum=momentum,                                        weight_decay=weight_decay)            torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=&#39;min&#39;, factor=0.1, patience=10, verbose=False,                                                       threshold=0.0001, threshold_mode=&#39;rel&#39;, cooldown=0, min_lr=0,                                                       eps=1e-08)                       inputs_train, labels_train = data_train            inputs_train, labels_train = Variable(inputs_train), Variable(labels_train) #variable封装tensor                        inputs_test, labels_test = next(data_gen)            inputs_test = torch.tensor(inputs_test)            labels_test = torch.tensor(labels_test)                        optimizer.zero_grad()            source_feature,source_result=model(inputs_train)            target_feature,target_result=model(inputs_test)            mmd_loss = mmd.mmd_rbf_noaccelerate(source_feature, target_feature)            loss = F.nll_loss(F.log_softmax(source_result,dim=1), labels_train.long())            lambd = 2 / (1 + math.exp(-10 * (e*train_num+j+1) / (epochs*train_num)))            loss_total = loss + lambd * mmd_loss            loss_total.backward()            optimizer.step()            prediction = torch.argmax(source_result,1)            correct +=(prediction == labels_train).sum().float()            total +=len(labels_train)            accuracy = correct/total            print(&quot;&#123;0:&lt;3d&#125; lr:&#123;1:&lt;.30f&#125;  loss:&#123;2:&lt;.20f&#125;  accuracy:&#123;3:&lt;.20f&#125;&quot;.format(j+1,lr_rate,loss_total,accuracy))</code></pre><h2 id="numpy和tensor转化"><a href="#numpy和tensor转化" class="headerlink" title="numpy和tensor转化"></a>numpy和tensor转化</h2><pre><code>train_feature_batch = torch.tensor(train_feature_batch)train_feature_batch = train_feature_batch.detach().numpy()</code></pre><h2 id="cuda选择"><a href="#cuda选择" class="headerlink" title="cuda选择"></a>cuda选择</h2><pre><code>import osos.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;2&quot;</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 迁移学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于脑机协同智能的情绪识别</title>
      <link href="2021/03/21/%E5%9F%BA%E4%BA%8E%E8%84%91%E6%9C%BA%E5%8D%8F%E5%90%8C%E6%99%BA%E8%83%BD%E7%9A%84%E6%83%85%E7%BB%AA%E8%AF%86%E5%88%AB/"/>
      <url>2021/03/21/%E5%9F%BA%E4%BA%8E%E8%84%91%E6%9C%BA%E5%8D%8F%E5%90%8C%E6%99%BA%E8%83%BD%E7%9A%84%E6%83%85%E7%BB%AA%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="基于脑机协同智能的情绪识别"><a href="#基于脑机协同智能的情绪识别" class="headerlink" title="基于脑机协同智能的情绪识别"></a>基于脑机协同智能的情绪识别</h1><blockquote><p>摘 要：面部表情识别是一种直接有效的情感识别模式。机器学习依靠对图像表情进行形式<br>化表征，缺乏大脑的认知表征能力，在小样本数据集或复杂表情（伪装）数据集上识别性能<br>并不理想。针对此问题，将机器人工智能的形式化表征与人脑通用智能的情感认知能力相结<br>合，提出一种脑机协同智能的情绪识别方法。首先，从脑电图信号中提取脑电情感特征以获<br>取大脑对于情绪的认知表征。其次，从情感图像中提取图像的视觉特征以获取机器对于情绪<br>的形式化表征。为增强机器模型的泛化能力，在特征学习中引入样本间的迁移适配。在得到<br>图像视觉特征和脑电情感特征后，采用随机森林回归模型训练得到图像视觉特征与脑电情感<br>特征之间的脑机映射关系。测试图像的图像视觉特征经过脑机映射关系产生虚拟脑电情感特<br>征，然后将虚拟脑电情感特征与图像视觉特征进行融合用于情绪识别。该方法已经在中国情<br>绪图片系统上进行了验证，发现对 7 种情绪的平均识别准确率为 88.51％，相比单纯基于图<br>像的方法提升 3%~5%。</p></blockquote><p>关键词：情绪识别；脑电图信号；脑机协同智能；深度学习</p><p>中图分类号：TP18，TN911.7，R318 </p><p>文献标识码：A </p><p>doi: 10.11959/j.issn.2096−6652.2021000</p>]]></content>
      
      
      
        <tags>
            
            <tag> 情绪识别 </tag>
            
            <tag> 脑机协同智能 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
