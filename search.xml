<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度学习零散知识点</title>
      <link href="2021/03/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9B%B6%E6%95%A3%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>2021/03/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9B%B6%E6%95%A3%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>#深度学习零散知识点</p><ol><li>reshape<pre><code>x_train = x_train.reshape(-1, height, width, channels).astype(&#39;float32&#39;)x_test = x_test.reshape(-1, height, width, channels).astype(&#39;float32&#39;)</code></pre>reshape更改数组形状，astype更改数值类型。</li><li>to_categorical<pre><code>y_train = np_utils.to_categorical(y_train, n_classes) y_test = np_utils.to_categorical(y_test, n_classes)</code></pre>to_categorical就是将类别向量转换为二进制（只有0和1）的矩阵类型表示。其表现为将原有的类别向量转换为独热（onehot）编码的形式。</li><li>keras数据增强<pre><code>datagen = ImageDataGenerator(     rotation_range=10,     width_shift_range=0.1,     height_shift_range=0.1,     horizontal_flip=True,     shear_range=0.1,     zoom_range=0.1,     fill_mode=&#39;nearest&#39;)</code></pre>图像深度学习任务中，面对小数据集，我们往往需要利用Image Data Augmentation图像增广技术来扩充我们的数据集，而keras的内置ImageDataGenerator很好地帮我们实现图像增广。</li><li>keras flow函数<pre><code>for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True):flow(self, X, y, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;png&#39;)：</code></pre>接收numpy数组和标签为参数,生成经过数据提升或标准化后的batch数据,并在一个无限循环中不断的返回batch数据,flow_from_directory(directory): 以文件夹路径为参数,生成经过数据提升/归一化后的数据,在一个无限循环中无限产生batch数据。</li><li>keras 自定义损失函数<pre><code>def dice_coef(y_true, y_pred, lamb): cross_loss= K.categorical_crossentropy(y_true,y_pred) mmd_loss = keras.losses.kullback_leibler_divergence(y_true,y_pred) return lamb * cross_loss + lamb * mmd_lossdef dice_loss(lamb): def dice(y_true, y_pred):     return dice_coef(y_true, y_pred, lamb) return dicedef my_loss(args, lamb): y_true, y_pred, train_feature, test_feature = args[0], args[1], args[2], args[3] mmd_loss = keras.losses.kullback_leibler_divergence(train_feature,test_feature) cross_loss= K.categorical_crossentropy(y_true,y_pred) return cross_loss + lamb*mmd_loss</code></pre></li><li>keras 训练，使用自定义损失函数<pre><code>model.add(Dense(n_classes,activation=&#39;softmax&#39;))train_features = model.predict(x_train)test_features = model.predict(x_test)train_features = tf.convert_to_tensor(train_features)test_features = tf.convert_to_tensor(test_features)y_pred = model.predict(x_train)y_true = y_trainy_pred = tf.convert_to_tensor(y_pred)y_true = tf.convert_to_tensor(y_true)loss_body = layers.Lambda(my_loss, output_shape=(1,), name=&#39;my_loss&#39;, arguments=&#123;&#39;lamb&#39;:0.5&#125;)([y_true, y_pred, train_features, test_features])model.add(loss_body)sgd = SGD(lr=lr, decay=1e-5, momentum=0.9, nesterov=False)model.compile(loss=&#123;&#39;my_loss&#39;: lambda y_true, y_pred: y_pred&#125;, optimizer=sgd)</code></pre></li><li>保存模型<pre><code>model.save(&#39;路径&#39;)</code></pre></li><li><pre><code>x_train = x_train.transpose(0, 3, 1, 2)x_test = x_test.transpose(0, 3, 1, 2)</code></pre>维度切换，将keras的AlextNet的输入的‘数量，长，宽，通道’修改为pytorch的‘数量，通道，长，宽’。</li><li>获取扩增数据，联系第3点<pre><code>x_train_all = []y_train_all = []batches_train=0for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True): x_train_all.append(x_batch) y_train_all.append(y_batch) batches_train+=1 if batches_train &gt;= times * len(x_train) / batch_size:     breakx_train_all = np.concatenate(x_train_all)y_train_all = np.concatenate(y_train_all)x_train_all = torch.tensor(x_train_all)y_train_all = torch.tensor(y_train_all)torch_data_train = GetLoader(x_train, y_train)  #dataloaderdatas_train = DataLoader(torch_data_train, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=0)</code></pre></li><li>pytorch 训练 迁移学习<pre><code>model.train()for e in range(epochs):    print(&#39;epochs:&#39;,e+1)    for j, data_train in enumerate(datas_train, 0):        lr_rate = lr / math.pow((1 +  (e * train_num + j) / epochs*train_num), 0.5)        optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate, momentum=momentum,                                    weight_decay=weight_decay)        torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=&#39;min&#39;, factor=0.1, patience=10, verbose=False,                                                   threshold=0.0001, threshold_mode=&#39;rel&#39;, cooldown=0, min_lr=0,                                                   eps=1e-08)        #source数据预处理        inputs_train, labels_train = data_train        #inputs_train, labels_train = Variable(inputs_train), Variable(labels_train) #variable封装tensor        #target数据预处理        inputs_test, labels_test = next(data_gen)        inputs_test = torch.tensor(inputs_test)        labels_test = torch.tensor(labels_test)        #DAN核心代码，封装在mmd模块中        optimizer.zero_grad() #梯度归零        source_feature,source_result=model(inputs_train)        target_feature,target_result=model(inputs_test)        mmd_loss = mmd.mmd_rbf_noaccelerate(source_feature, target_feature) #mmd损失函数        loss = F.nll_loss(F.log_softmax(source_result,dim=1), labels_train.long())        lambd = 2 / (1 + math.exp(-10 * (e*train_num+j+1) / (epochs*train_num))) - 1 #lamda值，公式里面的λ        loss_total = loss + lambd * mmd_loss  #总损失函数        loss_total.backward()  #反向传播梯度        optimizer.step()  #结束一次前传+反传之后，更新优化器参数        prediction = torch.argmax(source_result,1)        correct +=(prediction == labels_train).sum().float()        total +=len(labels_train)        accuracy = correct/total        print(&quot;&#123;0:&lt;3d&#125; lr:&#123;1:&lt;.30f&#125;  loss:&#123;2:&lt;.20f&#125;  accuracy:&#123;3:&lt;.20f&#125;&quot;.format(j+1,lr_rate,loss_total,accuracy))</code></pre></li><li>numpy和tensor转化<pre><code>train_feature_batch = torch.tensor(train_feature_batch)train_feature_batch = train_feature_batch.detach().numpy()</code></pre></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 迁移学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于脑机协同智能的情绪识别</title>
      <link href="2021/03/21/%E5%9F%BA%E4%BA%8E%E8%84%91%E6%9C%BA%E5%8D%8F%E5%90%8C%E6%99%BA%E8%83%BD%E7%9A%84%E6%83%85%E7%BB%AA%E8%AF%86%E5%88%AB/"/>
      <url>2021/03/21/%E5%9F%BA%E4%BA%8E%E8%84%91%E6%9C%BA%E5%8D%8F%E5%90%8C%E6%99%BA%E8%83%BD%E7%9A%84%E6%83%85%E7%BB%AA%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="基于脑机协同智能的情绪识别"><a href="#基于脑机协同智能的情绪识别" class="headerlink" title="基于脑机协同智能的情绪识别"></a>基于脑机协同智能的情绪识别</h1><blockquote><p>摘 要：面部表情识别是一种直接有效的情感识别模式。机器学习依靠对图像表情进行形式<br>化表征，缺乏大脑的认知表征能力，在小样本数据集或复杂表情（伪装）数据集上识别性能<br>并不理想。针对此问题，将机器人工智能的形式化表征与人脑通用智能的情感认知能力相结<br>合，提出一种脑机协同智能的情绪识别方法。首先，从脑电图信号中提取脑电情感特征以获<br>取大脑对于情绪的认知表征。其次，从情感图像中提取图像的视觉特征以获取机器对于情绪<br>的形式化表征。为增强机器模型的泛化能力，在特征学习中引入样本间的迁移适配。在得到<br>图像视觉特征和脑电情感特征后，采用随机森林回归模型训练得到图像视觉特征与脑电情感<br>特征之间的脑机映射关系。测试图像的图像视觉特征经过脑机映射关系产生虚拟脑电情感特<br>征，然后将虚拟脑电情感特征与图像视觉特征进行融合用于情绪识别。该方法已经在中国情<br>绪图片系统上进行了验证，发现对 7 种情绪的平均识别准确率为 88.51％，相比单纯基于图<br>像的方法提升 3%~5%。</p></blockquote><p>关键词：情绪识别；脑电图信号；脑机协同智能；深度学习</p><p>中图分类号：TP18，TN911.7，R318 </p><p>文献标识码：A </p><p>doi: 10.11959/j.issn.2096−6652.2021000</p>]]></content>
      
      
      
        <tags>
            
            <tag> 情绪识别 </tag>
            
            <tag> 脑机协同智能 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
